{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üìä Feature Engineering for Stock Clustering\n",
    "\n",
    "**Goal**: Transform raw stock prices into meaningful risk indicators.\n",
    "\n",
    "**Why?** Clustering algorithms need numeric features that capture different aspects of risk:\n",
    "- **Volatility**: How much the price swings\n",
    "- **Returns**: Profitability patterns\n",
    "- **Technical Indicators**: Market sentiment signals\n",
    "- **Liquidity**: How easy to trade\n",
    "- **Risk-adjusted performance**: Return vs risk tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from features import (\n",
    "    calculate_returns,\n",
    "    calculate_volatility_features,\n",
    "    calculate_risk_metrics,\n",
    "    calculate_technical_indicators,\n",
    "    calculate_liquidity_features,\n",
    "    calculate_momentum_features,\n",
    "    calculate_drawdown,\n",
    "    aggregate_stock_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05308946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69754 entries, 0 to 69753\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            69754 non-null  object \n",
      " 1   Stock_code      69754 non-null  object \n",
      " 2   Name            69754 non-null  object \n",
      " 3   12m Low         69754 non-null  float64\n",
      " 4   12m High        69754 non-null  float64\n",
      " 5   Day Low         69754 non-null  float64\n",
      " 6   Day High        69754 non-null  float64\n",
      " 7   Day Price       69754 non-null  float64\n",
      " 8   Previous        69754 non-null  float64\n",
      " 9   Change          69754 non-null  float64\n",
      " 10  %Change         69754 non-null  float64\n",
      " 11  Volume          69754 non-null  float64\n",
      " 12  Adjusted Price  69754 non-null  float64\n",
      " 13  Sector          69754 non-null  object \n",
      " 14  Month           69754 non-null  int64  \n",
      " 15  Year            69754 non-null  int64  \n",
      "dtypes: float64(10), int64(2), object(4)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/Processed/cleaned_nse.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "714a723c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ABSA\n",
       "1    ABSA\n",
       "2    ABSA\n",
       "3    ABSA\n",
       "4    ABSA\n",
       "Name: Stock_code, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stock_code'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_eng",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Feature Engineering Pipeline\n",
    "\n",
    "We'll apply 7 transformations to create ~25 features per stock:\n",
    "\n",
    "### A) Returns (Profitability)\n",
    "Daily returns show how much profit/loss each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "returns",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1/7: Calculating returns...\n",
      "Before - Index: None, Stock_code in columns? True\n",
      "After set_index - Index: Stock_code\n",
      "After groupby - Index: Stock_code, Stock_code in columns? True\n",
      "Dropped index (Stock_code already in columns)\n",
      "After reset_index - Stock_code in columns? True\n",
      "‚úÖ Added: daily_return, log_return\n",
      "Final columns: ['Date', 'Name', '12m Low', '12m High', 'Day Low', 'Day High', 'Day Price', 'Previous', 'Change', '%Change', 'Volume', 'Adjusted Price', 'Sector', 'Month', 'Year', 'daily_return', 'log_return', 'Stock_code']\n"
     ]
    }
   ],
   "source": [
    "# STEP 1\n",
    "print(\"Step 1/7: Calculating returns...\")\n",
    "print(f\"Before - Index: {df.index.name}, Stock_code in columns? {'Stock_code' in df.columns}\")\n",
    "\n",
    "# Handle the case where Stock_code is both index and column\n",
    "if df.index.name == 'Stock_code' and 'Stock_code' in df.columns:\n",
    "    # If it's both, just drop the index (don't try to add it again)\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"Dropped index (Stock_code already in columns)\")\n",
    "elif df.index.name == 'Stock_code':\n",
    "    # If it's only index, reset it to column\n",
    "    df = df.reset_index()\n",
    "    print(\"Reset Stock_code from index to column\")\n",
    "\n",
    "# Now set Stock_code as index\n",
    "df = df.set_index('Stock_code')\n",
    "print(f\"After set_index - Index: {df.index.name}\")\n",
    "\n",
    "# Apply calculations\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_returns, include_groups=False\n",
    ")\n",
    "print(f\"After groupby - Index: {df.index.name}, Stock_code in columns? {'Stock_code' in df.columns}\")\n",
    "\n",
    "# Reset index safely\n",
    "if 'Stock_code' in df.columns:\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"Dropped index (Stock_code already in columns)\")\n",
    "else:\n",
    "    df = df.reset_index()\n",
    "    print(\"Reset index to column\")\n",
    "\n",
    "print(f\"After reset_index - Stock_code in columns? {'Stock_code' in df.columns}\")\n",
    "print(f\"‚úÖ Added: daily_return, log_return\")\n",
    "print(f\"Final columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "volatility_md",
   "metadata": {},
   "source": [
    "### B) Volatility (Price Swings)\n",
    "Standard deviation of returns = how unpredictable the stock is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cc3b422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2/7: Calculating volatility...\n",
      "‚úÖ Added: volatility_7d, volatility_14d, volatility_30d\n"
     ]
    }
   ],
   "source": [
    "# STEP 2\n",
    "print(\"Step 2/7: Calculating volatility...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_volatility_features, include_groups=False\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\"‚úÖ Added: volatility_7d, volatility_14d, volatility_30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "risk_md",
   "metadata": {},
   "source": [
    "### C) Advanced Risk Metrics\n",
    "- **Downside deviation**: Only measures bad volatility (losses)\n",
    "- **Value at Risk (VaR)**: \"5% chance of losing this much or more\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b48918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3/7: Calculating risk metrics...\n",
      "‚úÖ Added: downside_deviation_30d, var_95\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Advanced Risk Metrics\n",
    "print(\"Step 3/7: Calculating risk metrics...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_risk_metrics, include_groups=False\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\"‚úÖ Added: downside_deviation_30d, var_95\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical_md",
   "metadata": {},
   "source": [
    "### D) Technical Indicators\n",
    "- **RSI** (0-100): <30 = oversold, >70 = overbought\n",
    "- **Bollinger Bands**: Volatility envelope around price\n",
    "- **MACD**: Trend momentum indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09246b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4/7: Calculating technical indicators...\n",
      " Added: rsi, bb_width, bb_position, macd, macd_signal\n",
      "Columns now: ['Stock_code', 'Date', 'Name', '12m Low', '12m High', 'Day Low', 'Day High', 'Day Price', 'Previous', 'Change', '%Change', 'Volume', 'Adjusted Price', 'Sector', 'Month', 'Year', 'daily_return', 'log_return', 'volatility_7d', 'volatility_14d', 'volatility_30d', 'downside_deviation_30d', 'var_95', 'rsi', 'bb_width', 'bb_position', 'macd', 'macd_signal']\n"
     ]
    }
   ],
   "source": [
    "# STEP 4: Technical Indicators\n",
    "print(\"Step 4/7: Calculating technical indicators...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_technical_indicators, include_groups=False\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\" Added: rsi, bb_width, bb_position, macd, macd_signal\")\n",
    "print(f\"Columns now: {df.columns.tolist()}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquidity_md",
   "metadata": {},
   "source": [
    "### E) Liquidity Features\n",
    "Can you buy/sell easily? High volume = liquid, low volume = illiquid (risky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "liquidity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5/7: Calculating liquidity features...\n",
      " Added: avg_volume, volume_volatility, volume_trend, amihud_illiquidity\n",
      "Stock_code in columns? True\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Liquidity Features\n",
    "print(\"Step 5/7: Calculating liquidity features...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_liquidity_features, include_groups=False\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\" Added: avg_volume, volume_volatility, volume_trend, amihud_illiquidity\")\n",
    "print(f\"Stock_code in columns? {'Stock_code' in df.columns}\")  # Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "momentum_md",
   "metadata": {},
   "source": [
    "### F) Momentum and Trends\n",
    "Is the stock going up/down/sideways? Comparing current price to moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6/7: Calculating momentum features...\n",
      " Added: momentum_7d, momentum_30d, momentum_90d, ma_7, ma_30, ma_50, price_to_ma30, price_to_ma50\n",
      "Stock_code in columns? True\n"
     ]
    }
   ],
   "source": [
    "# STEP 6: Momentum Features\n",
    "print(\"Step 6/7: Calculating momentum features...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_momentum_features, include_groups=False\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\" Added: momentum_7d, momentum_30d, momentum_90d, ma_7, ma_30, ma_50, price_to_ma30, price_to_ma50\")\n",
    "print(f\"Stock_code in columns? {'Stock_code' in df.columns}\")  # Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawdown_md",
   "metadata": {},
   "source": [
    "### G) Drawdown (Crash Risk)\n",
    "**Max Drawdown**: Largest peak-to-trough decline. Shows worst-case scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "drawdown",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7/7: Calculating drawdown metrics...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStep 7/7: Calculating drawdown metrics...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m df = df.set_index(\u001b[33m'\u001b[39m\u001b[33mStock_code\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcalculate_drawdown\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_groups\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This uses the imported function\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m df = df.reset_index()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Added: current_drawdown, max_drawdown, days_from_peak\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1821\u001b[39m, in \u001b[36mGroupBy.apply\u001b[39m\u001b[34m(self, func, include_groups, *args, **kwargs)\u001b[39m\n\u001b[32m   1818\u001b[39m     f = func\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m include_groups:\n\u001b[32m-> \u001b[39m\u001b[32m1821\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_obj_with_exclusions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1823\u001b[39m \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m   1824\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1887\u001b[39m, in \u001b[36mGroupBy._python_apply_general\u001b[39m\u001b[34m(self, f, data, not_indexed_same, is_transform, is_agg)\u001b[39m\n\u001b[32m   1852\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1853\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_python_apply_general\u001b[39m(\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1859\u001b[39m     is_agg: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1860\u001b[39m ) -> NDFrameT:\n\u001b[32m   1861\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1862\u001b[39m \u001b[33;03m    Apply function f in python space\u001b[39;00m\n\u001b[32m   1863\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1885\u001b[39m \u001b[33;03m        data after applying f\u001b[39;00m\n\u001b[32m   1886\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1887\u001b[39m     values, mutated = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grouper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_groupwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1888\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1889\u001b[39m         not_indexed_same = mutated\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:928\u001b[39m, in \u001b[36mBaseGrouper.apply_groupwise\u001b[39m\u001b[34m(self, f, data, axis)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[32m    927\u001b[39m group_axes = group.axes\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m res = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[32m    930\u001b[39m     mutated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mcalculate_drawdown\u001b[39m\u001b[34m(group)\u001b[39m\n\u001b[32m      6\u001b[39m group = group.copy()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Calculate running maximum\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m running_max = \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.expanding().max()\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Calculate drawdown\u001b[39;00m\n\u001b[32m     12\u001b[39m group[\u001b[33m'\u001b[39m\u001b[33mcurrent_drawdown\u001b[39m\u001b[33m'\u001b[39m] = (group[\u001b[33m'\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m'\u001b[39m] - running_max) / running_max\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'close'"
     ]
    }
   ],
   "source": [
    "# STEP 7: Drawdown Metrics\n",
    "print(\"Step 7/7: Calculating drawdown metrics...\")\n",
    "df = df.set_index('Stock_code')\n",
    "df = df.groupby(level=0, group_keys=False).apply(\n",
    "    calculate_drawdown, include_groups=False  # This uses the imported function\n",
    ")\n",
    "df = df.reset_index()\n",
    "print(f\"‚úÖ Added: current_drawdown, max_drawdown, days_from_peak\")\n",
    "print(f\"Stock_code in columns? {'Stock_code' in df.columns}\")\n",
    "\n",
    "print(f\"\\nFeature engineering complete!\")\n",
    "print(f\"Final DataFrame shape: {df.shape}\")\n",
    "print(f\"Final columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate_md",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Aggregate to Stock Level\n",
    "\n",
    "**Problem**: We have ~1000 rows per stock (one per day)\n",
    "\n",
    "**Solution**: Take **averages/medians** to get ONE row per stock\n",
    "\n",
    "**Key aggregated features**:\n",
    "- **Volatility**: mean, max\n",
    "- **Returns**: mean, std, skew, kurtosis\n",
    "- **Sharpe Ratio**: Return per unit of risk (CRUCIAL!)\n",
    "- **Technical**: RSI mean, Bollinger width, MACD volatility\n",
    "- **Liquidity**: volume, trading frequency, illiquidity\n",
    "- **Risk**: max drawdown, VaR, downside deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aggregate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating features to stock level...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'max_drawdown'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'max_drawdown'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m features_list = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m stock_code, group \u001b[38;5;129;01min\u001b[39;00m df.groupby(\u001b[33m'\u001b[39m\u001b[33mStock_code\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     stock_features = \u001b[43maggregate_stock_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stock_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      7\u001b[39m         features_list.append(stock_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\NSE_Stocks\\Notebooks\\../src\\features.py:173\u001b[39m, in \u001b[36maggregate_stock_features\u001b[39m\u001b[34m(group)\u001b[39m\n\u001b[32m    171\u001b[39m features[\u001b[33m'\u001b[39m\u001b[33mstd_return\u001b[39m\u001b[33m'\u001b[39m] = active_days[\u001b[33m'\u001b[39m\u001b[33mdaily_return\u001b[39m\u001b[33m'\u001b[39m].std()\n\u001b[32m    172\u001b[39m features[\u001b[33m'\u001b[39m\u001b[33mreturn_skew\u001b[39m\u001b[33m'\u001b[39m] = active_days[\u001b[33m'\u001b[39m\u001b[33mdaily_return\u001b[39m\u001b[33m'\u001b[39m].skew()\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m features[\u001b[33m'\u001b[39m\u001b[33mreturn_kurtosis\u001b[39m\u001b[33m'\u001b[39m] = active_days[\u001b[33m'\u001b[39m\u001b[33mdaily_return\u001b[39m\u001b[33m'\u001b[39m].kurtosis()\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# Sharpe ratio (risk-adjusted return) - CRITICAL FOR CLUSTERING\u001b[39;00m\n\u001b[32m    176\u001b[39m risk_free_rate = \u001b[32m0.0001\u001b[39m  \u001b[38;5;66;03m# ~2.5% annual = 0.01% daily\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'max_drawdown'"
     ]
    }
   ],
   "source": [
    "print(\"Aggregating features to stock level...\")\n",
    "\n",
    "features_list = []\n",
    "for stock_code, group in df.groupby('Stock_code'):\n",
    "    stock_features = aggregate_stock_features(group)\n",
    "    if stock_features is not None:\n",
    "        features_list.append(stock_features)\n",
    "\n",
    "df_features = pd.DataFrame(features_list)\n",
    "print(f\"\\n‚úÖ Created {len(df_features)} stock profiles with {len(df_features.columns)} features\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_md",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Inspect Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Statistics:\\n\")\n",
    "print(df_features[[\n",
    "    'volatility_mean', 'sharpe_ratio', 'max_drawdown', \n",
    "    'trading_frequency', 'rsi_mean', 'downside_deviation'\n",
    "]].describe().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_md",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../Data/Processed/nse_features.csv'\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Saved features to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Summary\n",
    "\n",
    "**What we did**:\n",
    "1. ‚úÖ Calculated returns and volatility (basic risk)\n",
    "2. ‚úÖ Added advanced risk metrics (downside dev, VaR)\n",
    "3. ‚úÖ Computed technical indicators (RSI, Bollinger, MACD)\n",
    "4. ‚úÖ Measured liquidity (volume, illiquidity)\n",
    "5. ‚úÖ Tracked momentum and trends (MAs, price ratios)\n",
    "6. ‚úÖ Analyzed drawdowns (max loss)\n",
    "7. ‚úÖ Aggregated ~1000 daily rows ‚Üí 1 stock profile\n",
    "\n",
    "**Key insight**: Clustering works MUCH better with diverse features that capture different risk dimensions.\n",
    "\n",
    "**Next**: Use these features for K-Means clustering! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
