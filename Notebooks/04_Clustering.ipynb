{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üéØ Stock Clustering by Risk Profile\n",
    "\n",
    "**Goal**: Group NSE stocks into 4 risk categories using K-Means clustering.\n",
    "\n",
    "**Why clustering?**\n",
    "- Helps investors find stocks matching their risk tolerance\n",
    "- Identifies natural risk patterns in the market\n",
    "- Creates diversified portfolio buckets\n",
    "\n",
    "**What makes good clusters?**\n",
    "- **Silhouette Score > 0.5**: Stocks within cluster are similar, different clusters are distinct\n",
    "- **Balanced sizes**: No cluster with too few stocks\n",
    "- **Clear interpretation**: Each cluster has a clear risk profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from clustering import find_optimal_clusters, StockClusterer\n",
    "\n",
    "# Styling\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_md",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Processed/nse_features.csv')\n",
    "print(f\"Loaded {len(df)} stocks with {len(df.columns)} features\")\n",
    "print(f\"\\nFeature names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimal_md",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Find Optimal Number of Clusters\n",
    "\n",
    "**Elbow Method**: Look for \"elbow\" where inertia stops dropping fast\n",
    "\n",
    "**Silhouette Score**: Measures cluster quality (0.5+ is good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test features for clustering\n",
    "feature_cols = [\n",
    "    'volatility_mean', 'volatility_max', 'downside_deviation',\n",
    "    'std_return', 'var_95', 'max_drawdown',\n",
    "    'sharpe_ratio', 'return_skew', 'return_kurtosis',\n",
    "    'rsi_mean', 'bb_width_mean', 'macd_volatility',\n",
    "    'momentum_30d', 'momentum_90d', 'trend_strength',\n",
    "    'trading_frequency', 'amihud_illiquidity',\n",
    "    'volume_volatility', 'avg_recovery_days'\n",
    "]\n",
    "\n",
    "# Only use features that exist\n",
    "feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "print(f\"Using {len(feature_cols)} features for clustering\\n\")\n",
    "\n",
    "cluster_metrics = find_optimal_clusters(df, feature_cols, max_clusters=8)\n",
    "print(cluster_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Elbow plot\n",
    "ax1.plot(cluster_metrics['n_clusters'], cluster_metrics['inertia'], 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_title('Elbow Method - Find Inertia Drop', fontweight='bold', fontsize=14)\n",
    "ax1.set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax1.set_ylabel('Inertia (Within-cluster variance)', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Silhouette plot\n",
    "ax2.plot(cluster_metrics['n_clusters'], cluster_metrics['silhouette'], 'ro-', linewidth=2, markersize=8)\n",
    "ax2.axhline(y=0.5, color='g', linestyle='--', label='Good threshold (0.5)', linewidth=2)\n",
    "ax2.set_title('Silhouette Score - Cluster Quality', fontweight='bold', fontsize=14)\n",
    "ax2.set_xlabel('Number of Clusters', fontsize=12)\n",
    "ax2.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_k = cluster_metrics.loc[cluster_metrics['silhouette'].idxmax(), 'n_clusters']\n",
    "print(f\"\\nüéØ Recommended: {int(best_k)} clusters (highest silhouette score)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cluster_md",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Perform Clustering\n",
    "\n",
    "Using **4 clusters** for risk profiles:\n",
    "1. Low Risk\n",
    "2. Medium-Low Risk\n",
    "3. Medium-High Risk\n",
    "4. High Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cluster",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = StockClusterer(n_clusters=4, random_state=42)\n",
    "df_clustered = clusterer.fit_predict(df)\n",
    "\n",
    "print(f\"\\nüìä Cluster Distribution:\")\n",
    "print(df_clustered['Risk_Profile'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize_md",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Visualize Clusters\n",
    "\n",
    "**PCA** reduces 19+ dimensions to 2D for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PCA\n",
    "X = df_clustered[clusterer.feature_columns].fillna(df_clustered[clusterer.feature_columns].median())\n",
    "X_scaled = clusterer.scaler.transform(X)\n",
    "\n",
    "# PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 9))\n",
    "colors = ['green', 'blue', 'orange', 'red']\n",
    "labels = ['Low Risk', 'Medium-Low Risk', 'Medium-High Risk', 'High Risk']\n",
    "\n",
    "for i, (color, label) in enumerate(zip(colors, labels)):\n",
    "    mask = df_clustered['Risk_Profile'] == label\n",
    "    plt.scatter(X_pca[mask, 0], X_pca[mask, 1],\n",
    "                c=color, label=f\"{label} ({mask.sum()})\",\n",
    "                alpha=0.7, s=150, edgecolors='black', linewidth=1.5)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=13, fontweight='bold')\n",
    "plt.title('NSE Stock Risk Clusters (PCA Projection)', fontsize=16, fontweight='bold')\n",
    "plt.legend(title='Risk Profile', title_fontsize=12, fontsize=11, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüí° PCA explains {pca.explained_variance_ratio_[:2].sum():.1%} of total variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_md",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Cluster Profiles\n",
    "\n",
    "Compare clusters across key metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = clusterer.get_cluster_summary(df_clustered)\n",
    "print(\"\\nüìà Cluster Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "samples_md",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Sample Stocks by Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "samples",
   "metadata": {},
   "outputs": [],
   "source": [
    "for risk in ['Low Risk', 'Medium-Low Risk', 'Medium-High Risk', 'High Risk']:\n",
    "    subset = df_clustered[df_clustered['Risk_Profile'] == risk]\n",
    "    if len(subset) > 0:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{risk.upper()} ({len(subset)} stocks)\")\n",
    "        print('='*60)\n",
    "        \n",
    "        cols = ['Stock_code', 'Name', 'Sector', 'volatility_mean', 'sharpe_ratio']\n",
    "        available_cols = [c for c in cols if c in subset.columns]\n",
    "        \n",
    "        sample = subset.nsmallest(5, 'volatility_mean')[available_cols]\n",
    "        print(sample.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_md",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save clustered data\n",
    "df_clustered.to_csv('../Data/Processed/nse_clustered.csv', index=False)\n",
    "print(\"‚úÖ Saved clustered data\")\n",
    "\n",
    "# Save model\n",
    "clusterer.save_model('../models/stock_clusterer.pkl')\n",
    "print(\"‚úÖ Saved trained model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Summary\n",
    "\n",
    "**What we did**:\n",
    "1. ‚úÖ Tested 2-8 clusters using elbow method and silhouette scores\n",
    "2. ‚úÖ Chose 4 clusters for risk profiles\n",
    "3. ‚úÖ Trained K-Means with 19 advanced features\n",
    "4. ‚úÖ Visualized clusters in 2D using PCA\n",
    "5. ‚úÖ Analyzed cluster characteristics\n",
    "6. ‚úÖ Saved model and results\n",
    "\n",
    "**Key improvement**: Using advanced features (Sharpe ratio, technical indicators, risk metrics) dramatically improves clustering quality compared to basic volatility alone.\n",
    "\n",
    "**Next**: Evaluate model performance and generate insights! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
